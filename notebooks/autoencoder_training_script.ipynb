{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow.keras.layers\n",
    "import keras\n",
    "\n",
    "#Defining the input image size - chosen so it can be recreated easily\n",
    "input_img = Input(shape=(320, 192, 3))\n",
    "\n",
    "#Model architecture definition\n",
    "#Consists of convultional layers to help learn the features of the clothing item - sleeve type, striped, collar type, etc\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
    "autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"Zipped_final.zip\", 'r')\n",
    "zip_ref.extractall(\"/tmp\")\n",
    "zip_ref.close()\n",
    "\n",
    "\n",
    "#Loading in the data and resizing the images\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "col_dir = '/tmp/Zipped/Amazon Images/*.jpg'\n",
    "col_amazon = imread_collection(col_dir)\n",
    "col_amazon = list(col_amazon)\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "for i in range(len(col_amazon)):\n",
    "    col_amazon[i] = resize(col_amazon[i], (320, 192, 3))\n",
    "\n",
    "col_dir = '/tmp/Zipped/Flipkart Images/*.jpg'\n",
    "col_fk = imread_collection(col_dir)\n",
    "col_fk = list(col_fk)\n",
    "\n",
    "for i in range(len(col_fk)):\n",
    "    col_fk[i] = resize(col_fk[i], (320, 192, 3))\n",
    "\n",
    "col_dir = '/tmp/Zipped/Myntra Images/*.jpg'\n",
    "col_myntra = imread_collection(col_dir)\n",
    "col_myntra = list(col_myntra)\n",
    "\n",
    "for i in range(len(col_myntra)):\n",
    "    col_myntra[i] = resize(col_myntra[i], (320, 192, 3))\n",
    "\n",
    "col_dir = '/tmp/Zipped/Pinterest Men Images/*.jpg'\n",
    "col_pinmen = imread_collection(col_dir)\n",
    "col_pinmen = list(col_pinmen)\n",
    "\n",
    "for i in range(len(col_pinmen)):\n",
    "    col_pinmen[i] = resize(col_pinmen[i], (320, 192, 3))\n",
    "\n",
    "col_dir = '/tmp/Zipped/Pinterest Women Images/*.jpg'\n",
    "col_pinwom = imread_collection(col_dir)\n",
    "col_pinwom = list(col_pinwom)\n",
    "\n",
    "for i in range(len(col_pinwom)):\n",
    "    col_pinwom[i] = resize(col_pinwom[i], (320, 192, 3))\n",
    "\n",
    "col_dir = '/tmp/Zipped/Vogue Images/*.jpg'\n",
    "col_vog = imread_collection(col_dir)\n",
    "col_vog = list(col_vog)\n",
    "\n",
    "for i in range(len(col_vog)):\n",
    "    col_vog[i] = resize(col_vog[i], (320, 192, 3))\n",
    "\n",
    "col_clothes = col_amazon+col_fk+col_pinmen+col_vog+col_myntra+col_pinwom\n",
    "\n",
    "x_train = np.array(col_clothes[0:3000])\n",
    "x_test = np.array(col_clothes[3000:])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Training the model\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "#Saving the model\n",
    "encoder = Model(input_img, encoded)\n",
    "encoder.save(\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-providence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
